//++++
//<link rel="stylesheet"  href="http://cdnjs.cloudflare.com/ajax/libs/font-awesome/3.1.0/css/font-awesome.min.css">
//++++
:icons: font
:source-language: shell
:numbered:
// Activate experimental attribute for Keyboard Shortcut keys
:experimental:
:source-highlighter: pygments
:sectnums:
:sectnumlevels: 6
:toc: left
:toclevels: 4

== Introduction

[abstract]
In this hands‑on lab you will stand up a miniature—but fully functional—zero‑trust data lake that lives on *Ceph Object Gateway (RGW)* and is governed by the *Polaris* data‑catalog.  
You will automate the infrastructure with Terraform, ingest data with Spark, query it with Trino, and visualise it in Superset—while watching catalog‑level RBAC enforce least‑privilege at every step.

=== What you will build

[source,mermaid]
----
flowchart TD
    subgraph Ceph_UI ["Ceph dashboard"]
        CD1["Login"] --> CD2["Create RGW account & root user"]
    end
    subgraph IaC ["Terraform"]
        TF1["ceph/ bucket + IAM"] --> TF2["polaris/ principals, grants, tables"]
    end
    subgraph Containers ["Runtime services"]
        DK1["docker compose up → Polaris • Trino • Jupyter • Superset"]
    end
    subgraph Pipeline ["Data pipeline"]
        direction LR
        E1["Engineer → products_raw (Spark)"]
        C1["Compliance → products_gold (Spark)"]
        A1["Analyst → query (Trino)"]
        A2["Analyst → dashboard (Superset)"]
    end
    CD2 --> TF1
    TF2 --> DK1
    DK1 --> E1 --> C1 --> A1 --> A2
----

=== Core skills you’ll practise

|===
| Pillar | You’ll learn to…

| *Storage*
| Create Ceph RGW buckets and IAM roles from the dashboard and Terraform.

| *Infrastructure‑as‑Code*
| Bootstrap all catalog objects (principals, grants, tables) with a single `terraform apply`.

| *Data Engineering*
| Use Spark to ingest CSV → Iceberg and to overwrite snapshots safely.

| *Governance / Security*
| Enforce role‑based access with Polaris tokens; watch failures when a role steps outside its lane.

| *Analytics*
| Query the same Iceberg tables from Trino CLI and render a Superset dashboard—all without additional credentials.

| *Lifecycle hygiene*
| Tear everything down cleanly with `./demo.sh destroy`.
|===

=== Lab flow at a glance

. *Login to Ceph Dashboard* – create RGW account & root user.  
. *Run Terraform (`ceph/`)* – wire bucket & IAM.  
. *Run Terraform (`polaris/`)* – create catalog, principals, RAW + GOLD tables.  
. *Start containers* – Polaris, Trino, Jupyter, Superset in one command.  
. *Engineer persona* – ingest `products_raw` in a Jupyter notebook.  
. *Compliance persona* – mask PII into `products_gold`.  
. *Analyst persona* – query GOLD via Trino and craft a Superset dashboard.  
. *Wrap‑up* – destroy resources and recap key take‑aways.

=== Estimated time

*90 minutes*

=== Provided for you

* Pre‑deployed IBM Storage Ceph RGW cluster.  
* Lab repository with Terraform code, notebooks, helper scripts, and a 200‑row sample CSV.  
* Pre‑generated Polaris tokens for the three personas.

== Checking the current state of the lab

If you are reading this doc, you should have your IBM Storage Ceph
Troubleshooting TechZone Lab up and running. If that is not the case, please go
to the IBM Storage Ceph Tech-Zone Collection and Order the troubleshooting Lab https://techzone.ibm.com/collection/64b92c8897187f0017773310)[TechZone Lab Access]

We must open a CLI terminal in our workstation machine and sudo to run the
lab commands as the `ROOT` user. The workstation has the required ceph client
RPMs and the CephX admin keys for our deployment so that
we can run most of the necessary commands for this lab from the workstation.

----
$ sudo -i
# ceph -s
  cluster:
    id:     09f357c6-b8d6-11ef-bbb7-02009a7a348a
    health: HEALTH_OK

  services:
    mon: 4 daemons, quorum ceph-node1-675b5683b75e66c49dc8f254,ceph-node2-675b5683b75e66c49dc8f254,ceph-node3-675b5683b75e66c49dc8f254,ceph-node4-675b5683b75e66c49dc8f254 (age 9h)
    mgr: ceph-node1-675b5683b75e66c49dc8f254.vadpyr(active, since 9h), standbys: ceph-node2-675b5683b75e66c49dc8f254.yuzazl
    osd: 12 osds: 12 up (since 9h), 12 in (since 9h)
    rgw: 1 daemon active (1 hosts, 1 zones)

  data:
    volumes: 1/1 healthy
    pools:   9 pools, 465 pgs
    objects: 250 objects, 456 KiB
    usage:   856 MiB used, 119 GiB / 120 GiB avail
    pgs:     465 active+clean

  io:
    client:   85 B/s rd, 0 op/s rd, 0 op/s wr
----

== Creating the required S3 IAM Account and Root Account User

=== Creating the IAM Account
=== Creating the Root User for the IAM Account
=== Verification

== Configure and Run the Terraform Automation Code to Create Required Ceph RGW resources

=== Modify Variables
=== Run Terraform
=== Verify 

== Deploy our Demo Analytical Container Stack

== Introduction
== Deployment with Podman Compose
== Verification

== Bootstrap a Polaris data catalog via Terraform

=== Modify Variables
=== Run Terraform
=== Verify

== Data pipeline execution with Jupiter Notebook 

== 


[IMPORTANT]
====
From this point forward, the guide will help you fix the issues one by one. **We recommend that you first try resolving the cluster problems on your own.** If you get stuck, refer to this guide for assistance.
====


[TIP]
====
====
