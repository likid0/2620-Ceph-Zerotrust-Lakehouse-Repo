#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

services:
  polaris:
    image: quay.io/polaris-catalog/polaris:s3compatible
    ports:
      - "8181:8181"
      - "8182:8182"
    env_file: .compose-aws.env
    environment:
      POLARIS_BOOTSTRAP_CREDENTIALS: default-realm,root,s3cr3t
      polaris.realm-context.realms: default-realm
      quarkus.otel.sdk.disabled: "true"
    container_name: polaris

  trino:
    image: trinodb/trino:latest
    container_name: trino
    depends_on:
      - polaris
    ports:
      - "8080:8080"
    volumes:
      - ./trino/catalog:/etc/trino/catalog
    environment:
      - JAVA_TOOL_OPTIONS=-Duser.timezone=UTC


  spark:
    image: bitnami/spark:3.5
    depends_on:
      - polaris
    ports: 
#      - 8080:8080  # Master Web UI
      - 7077:7077  # Master Port
    environment:
      SPARK_SUBMIT_OPTIONS: >
        --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.1,org.apache.hadoop:hadoop-aws:3.4.0
    env_file: .compose-aws.env 
    container_name: spark
    volumes:
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro

  jupyter:
    image: jupyter/pyspark-notebook:spark-3.5.0
    container_name: jupyter
    depends_on:
      - spark
    ports:
      - "8888:8888"
    env_file: .compose-aws.env
    environment:
      SPARK_OPTS: >
        --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.7.1,
                  org.apache.hadoop:hadoop-aws:3.4.0
    volumes:
      - ./notebooks:/home/jovyan/work
    container_name: jupiter

  superset:
    image: docker.io/apache/superset:latest
    container_name: superset
    depends_on:
      - trino                           # waits until Trino is healthy
    ports:
      - "8088:8088"
    env_file: .compose-aws.env          # passes S3 creds if you later add S3 drivers
    environment:
      # ‑‑ Mandatory secret for Flask sessions
      SUPERSET_SECRET_KEY: "oh-so-secret"
      # ‑‑ Auto‑create the initial admin user on first run
      ADMIN_USERNAME: "admin"
      ADMIN_FIRST_NAME: "Admin"
      ADMIN_LAST_NAME: "User"
      ADMIN_EMAIL: "admin@example.com"
      ADMIN_PASSWORD: "admin"           # change in production!
      # Optional: skip loading example dashboards
      SUPERSET_LOAD_EXAMPLES: "no"
    volumes:
      - superset_home:/app/superset_home
    command: >
      /bin/bash -c "
        superset db upgrade &&
        superset fab create-admin \
          --username \$ADMIN_USERNAME \
          --firstname \$ADMIN_FIRST_NAME \
          --lastname \$ADMIN_LAST_NAME \
          --email \$ADMIN_EMAIL \
          --password \$ADMIN_PASSWORD || true &&
        superset init &&
        superset run -h 0.0.0.0 -p 8088
      "
volumes:
  superset_home: {}
